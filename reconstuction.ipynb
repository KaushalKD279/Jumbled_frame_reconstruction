{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOr//Fjg6bQN6PbLLSeLwlm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaushalKD279/Jumbled_frame_reconstruction/blob/main/reconstuction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNvuoiDdzFe2",
        "outputId": "5680a15f-6f46-4bf4-9df3-644563572cff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mImports done.\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# CELL 1: Install dependencies & imports\n",
        "# ========================================\n",
        "!pip install -q opencv-python-headless torch torchvision tqdm scikit-learn gdown\n",
        "\n",
        "import os\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import gdown\n",
        "import warnings\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "warnings.filterwarnings('ignore')\n",
        "print(\"Imports done.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# CELL 2: Download jumbled video (Google Drive)\n",
        "# ========================================\n",
        "file_id = \"1DbR9yap-vgUaPiI3hCEKUnniXr-TrdOt\"\n",
        "output = \"jumbled_video.mp4\"\n",
        "print(\"Downloading jumbled video...\")\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output, quiet=False)\n",
        "print(\"Download complete:\", output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgT3nZoYzSpr",
        "outputId": "b2ba6f96-e677-49f7-acd4-2c6dcb17e06b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading jumbled video...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1DbR9yap-vgUaPiI3hCEKUnniXr-TrdOt\n",
            "To: /content/jumbled_video.mp4\n",
            "100%|██████████| 90.6M/90.6M [00:01<00:00, 77.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download complete: jumbled_video.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# CELL 3: Optimized FrameReconstructor (batched features, GPU similarity, in-memory frames, limited 2-opt)\n",
        "# ========================================\n",
        "import math\n",
        "from typing import List, Tuple\n",
        "\n",
        "class FrameReconstructorOptimized:\n",
        "    def __init__(self, device=None, use_deep_features=True, model_name='resnet50'):\n",
        "        # pick device\n",
        "        if device is None:\n",
        "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        else:\n",
        "            self.device = device\n",
        "        self.use_deep_features = use_deep_features\n",
        "        self.model_name = model_name\n",
        "        self.model = None\n",
        "        self.transform = None\n",
        "        if self.use_deep_features:\n",
        "            self._init_feature_extractor()\n",
        "        print(f\"Initialized reconstructor on device={self.device}, deep_features={self.use_deep_features}\")\n",
        "\n",
        "    def _init_feature_extractor(self):\n",
        "        # Use torchvision ResNet backbone without final FC: outputs (B, 2048, 1, 1)\n",
        "        print(\"Initializing feature extractor:\", self.model_name)\n",
        "        if self.model_name == 'resnet50':\n",
        "            base = models.resnet50(pretrained=True)\n",
        "        elif self.model_name == 'resnet18':\n",
        "            base = models.resnet18(pretrained=True)\n",
        "        else:\n",
        "            base = models.resnet50(pretrained=True)\n",
        "\n",
        "        # strip fc layer\n",
        "        self.model = torch.nn.Sequential(*list(base.children())[:-1]).to(self.device)\n",
        "        self.model.eval()\n",
        "\n",
        "        # transform pipeline\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        # warmup\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.zeros(1, 3, 224, 224).to(self.device)\n",
        "            self.model(dummy)\n",
        "        print(\"Feature extractor ready on\", self.device)\n",
        "\n",
        "    def extract_frames_in_memory(self, video_path: str) -> Tuple[List[np.ndarray], float, float]:\n",
        "        \"\"\"Decode video fully into a list of BGR numpy arrays (in-memory). Returns frames, fps, frame_count\"\"\"\n",
        "        start = time.time()\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
        "        frames = []\n",
        "        frame_count = 0\n",
        "        pbar = tqdm(total=int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0), desc=\"Decoding frames\", unit=\"f\")\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frames.append(frame)  # BGR numpy array\n",
        "            frame_count += 1\n",
        "            pbar.update(1)\n",
        "        pbar.close()\n",
        "        cap.release()\n",
        "        elapsed = time.time() - start\n",
        "        print(f\"Decoded {frame_count} frames at {fps:.2f} FPS in {elapsed:.2f}s\")\n",
        "        return frames, fps, elapsed\n",
        "\n",
        "    def _batchify_and_extract(self, frames: List[np.ndarray], batch_size: int = 32) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Convert frames (BGR numpy arrays) into batched tensors and run through model.\n",
        "        Returns numpy array shape (N, feat_dim).\n",
        "        \"\"\"\n",
        "        N = len(frames)\n",
        "        feats_list = []\n",
        "        to_tensor = self.transform\n",
        "        device = self.device\n",
        "\n",
        "        # Preconvert to tensors to avoid redundant CPU->GPU ops\n",
        "        # We'll build batches of tensors on CPU then stack and send to GPU\n",
        "        tensors_cpu = []\n",
        "        for img in frames:\n",
        "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            t = to_tensor(img_rgb)\n",
        "            tensors_cpu.append(t)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i in tqdm(range(0, N, batch_size), desc=\"Extracting features (batched)\"):\n",
        "                batch = torch.stack(tensors_cpu[i:i+batch_size]).to(device)  # (B,3,224,224)\n",
        "                out = self.model(batch)  # (B, feat, 1, 1)\n",
        "                out = out.view(out.size(0), -1)  # (B, feat_dim)\n",
        "                feats_list.append(out.cpu().numpy())\n",
        "\n",
        "        feats = np.concatenate(feats_list, axis=0)\n",
        "        return feats  # (N, feat_dim)\n",
        "\n",
        "    def compute_features(self, frames: List[np.ndarray], batch_size: int = 32) -> Tuple[np.ndarray, float]:\n",
        "        \"\"\"Public: compute features for all frames and return (features, elapsed_time)\"\"\"\n",
        "        t0 = time.time()\n",
        "        if self.use_deep_features:\n",
        "            feats = self._batchify_and_extract(frames, batch_size=batch_size)\n",
        "        else:\n",
        "            # fallback: color histograms (fast, CPU)\n",
        "            feats = []\n",
        "            for img in tqdm(frames, desc=\"Histogram features\"):\n",
        "                small = cv2.resize(img, (64, 64))\n",
        "                hist = cv2.calcHist([small], [0,1,2], None, [8,8,8], [0,256,0,256,0,256])\n",
        "                feats.append(hist.flatten())\n",
        "            feats = np.array(feats)\n",
        "        elapsed = time.time() - t0\n",
        "        print(f\"Feature extraction done: shape={feats.shape} time={elapsed:.2f}s\")\n",
        "        return feats, elapsed\n",
        "\n",
        "    def build_similarity_matrix(self, features: np.ndarray) -> Tuple[np.ndarray, float]:\n",
        "        \"\"\"\n",
        "        Build cosine similarity matrix using torch on device (fast).\n",
        "        Returns S as numpy array on CPU.\n",
        "        \"\"\"\n",
        "        t0 = time.time()\n",
        "        device = self.device\n",
        "        with torch.no_grad():\n",
        "            feats_t = torch.from_numpy(features).float().to(device)  # (N, dim)\n",
        "            # normalize rows\n",
        "            norms = feats_t.norm(dim=1, keepdim=True).clamp(min=1e-8)\n",
        "            feats_t = feats_t / norms\n",
        "            # compute cosine similarity via matrix multiplication\n",
        "            S_t = torch.mm(feats_t, feats_t.t())  # (N,N) on device\n",
        "            # clamp numeric noise\n",
        "            S_t = S_t.clamp(-1.0, 1.0)\n",
        "            S = S_t.cpu().numpy()\n",
        "        elapsed = time.time() - t0\n",
        "        print(f\"Built similarity matrix (N={S.shape[0]}) in {elapsed:.2f}s\")\n",
        "        return S, elapsed\n",
        "\n",
        "    def greedy_path_from_sim(self, S: np.ndarray, start_idx: int = None) -> Tuple[List[int], float]:\n",
        "        t0 = time.time()\n",
        "        N = S.shape[0]\n",
        "        if start_idx is None:\n",
        "            start_idx = int(np.argmax(np.sum(S, axis=1)))\n",
        "        path = [start_idx]\n",
        "        remaining = set(range(N)) - {start_idx}\n",
        "        # greedy: always pick argmax similarity to current\n",
        "        while remaining:\n",
        "            cur = path[-1]\n",
        "            rem_list = np.array(list(remaining))\n",
        "            sims = S[cur, rem_list]\n",
        "            # argmax\n",
        "            arg = int(np.argmax(sims))\n",
        "            nxt = int(rem_list[arg])\n",
        "            path.append(nxt)\n",
        "            remaining.remove(nxt)\n",
        "        elapsed = time.time() - t0\n",
        "        print(f\"Greedy path computed in {elapsed:.2f}s\")\n",
        "        return path, elapsed\n",
        "\n",
        "    def two_opt_limited(self, path: List[int], S: np.ndarray, max_iter: int = 200, top_k: int = 15) -> Tuple[List[int], float]:\n",
        "        \"\"\"\n",
        "        2-opt with neighborhood limitation:\n",
        "        - Precompute top_k neighbors for each node.\n",
        "        - When considering swapping edges, only attempt k values where improvement is likely.\n",
        "        Uses fast delta-cost computation for swaps.\n",
        "        \"\"\"\n",
        "        t0 = time.time()\n",
        "        N = len(path)\n",
        "        # Precompute top_k neighbors (sorted descending)\n",
        "        topk = np.argsort(-S, axis=1)[:, :top_k]  # (N, top_k)\n",
        "        # position lookup\n",
        "        pos = np.empty(N, dtype=int)\n",
        "        for idx, node in enumerate(path):\n",
        "            pos[node] = idx\n",
        "\n",
        "        improved = True\n",
        "        it = 0\n",
        "        # Helper to compute delta for reversing segment (i..k)\n",
        "        def delta_cost(a_idx, b_idx, c_idx, d_idx):\n",
        "            # change when replacing edges (a->b) & (c->d) with (a->c) & (b->d)\n",
        "            return (S[a_idx, c_idx] + S[b_idx, d_idx]) - (S[a_idx, b_idx] + S[c_idx, d_idx])\n",
        "\n",
        "        while improved and it < max_iter:\n",
        "            improved = False\n",
        "            it += 1\n",
        "            # iterate through nodes by position\n",
        "            for i in range(1, N-2):\n",
        "                a = path[i-1]\n",
        "                b = path[i]\n",
        "                # consider only c candidates that are among top neighbors of 'a' or 'b'\n",
        "                candidate_nodes = set()\n",
        "                candidate_nodes.update(topk[a])\n",
        "                candidate_nodes.update(topk[b])\n",
        "                # filter positions > i (k >= i+1)\n",
        "                for c in candidate_nodes:\n",
        "                    kpos = pos[c]\n",
        "                    # we need kpos > i (we'll reverse b..c)\n",
        "                    if not (kpos > i):\n",
        "                        continue\n",
        "                    c_node = path[kpos]\n",
        "                    d_node = path[kpos+1] if (kpos+1 < N) else None\n",
        "                    if d_node is None:\n",
        "                        continue\n",
        "                    # compute improvement delta\n",
        "                    dlt = delta_cost(a, b, c_node, d_node)\n",
        "                    if dlt > 1e-6:  # positive dlt means similarity increases (good)\n",
        "                        # perform reversal between i and kpos\n",
        "                        path[i:kpos+1] = path[i:kpos+1][::-1]\n",
        "                        # update positions\n",
        "                        for j in range(i, kpos+1):\n",
        "                            pos[path[j]] = j\n",
        "                        improved = True\n",
        "                        break\n",
        "                if improved:\n",
        "                    break\n",
        "        elapsed = time.time() - t0\n",
        "        print(f\"2-opt limited finished in {it} iterations, time={elapsed:.2f}s\")\n",
        "        return path, elapsed\n",
        "\n",
        "    def write_ordered_video_in_memory(self, path_order: List[int], frames: List[np.ndarray], output_path: str, fps: float):\n",
        "        \"\"\"Write the reordered frames to an mp4 file using VideoWriter (frames are in memory)\"\"\"\n",
        "        t0 = time.time()\n",
        "        if len(path_order) == 0:\n",
        "            raise ValueError(\"Empty path order.\")\n",
        "        first_frame = frames[path_order[0]]\n",
        "        h, w = first_frame.shape[:2]\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_path, fourcc, fps, (w, h))\n",
        "        for idx in tqdm(path_order, desc=\"Writing video\"):\n",
        "            frame = frames[idx]\n",
        "            out.write(frame)\n",
        "        out.release()\n",
        "        elapsed = time.time() - t0\n",
        "        print(f\"Wrote video to {output_path} in {elapsed:.2f}s\")\n",
        "        return elapsed\n",
        "\n",
        "    def reconstruct(self, video_path: str, output_path: str = 'reconstructed.mp4', batch_size:int = 32, two_opt_iters:int = 200, top_k:int = 15):\n",
        "        \"\"\"Complete pipeline returning path and timings dict\"\"\"\n",
        "        timings = {}\n",
        "        total_t0 = time.time()\n",
        "\n",
        "        # 1. Decode frames into memory\n",
        "        frames, fps, t_decode = self.extract_frames_in_memory(video_path)\n",
        "        timings['decode'] = t_decode\n",
        "        N = len(frames)\n",
        "        if N == 0:\n",
        "            raise ValueError(\"No frames decoded.\")\n",
        "\n",
        "        # 2. Feature extraction (batched)\n",
        "        feats, t_feat = self.compute_features(frames, batch_size=batch_size)\n",
        "        timings['feature_extraction'] = t_feat\n",
        "\n",
        "        # 3. Similarity matrix (GPU then to CPU)\n",
        "        S, t_sim = self.build_similarity_matrix(feats)\n",
        "        timings['similarity_matrix'] = t_sim\n",
        "\n",
        "        # 4. Greedy initial path\n",
        "        path, t_greedy = self.greedy_path_from_sim(S)\n",
        "        timings['greedy_path'] = t_greedy\n",
        "\n",
        "        # 5. 2-opt limited\n",
        "        path, t_twoopt = self.two_opt_limited(path, S, max_iter=two_opt_iters, top_k=top_k)\n",
        "        timings['two_opt'] = t_twoopt\n",
        "\n",
        "        # 6. Write reordered video\n",
        "        t_write = self.write_ordered_video_in_memory(path, frames, output_path, fps=fps)\n",
        "        timings['video_writing'] = t_write\n",
        "\n",
        "        timings['total'] = time.time() - total_t0\n",
        "        print(\"Timings:\", timings)\n",
        "        return path, timings\n"
      ],
      "metadata": {
        "id": "ZZ2uLJfozaAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# CELL 4: Run the optimized reconstruction\n",
        "# ========================================\n",
        "# Check device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Using device:\", device)\n",
        "if device == 'cuda':\n",
        "    try:\n",
        "        print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "# initialize reconstructor (choose resnet18 for speed if you want)\n",
        "reconstructor = FrameReconstructorOptimized(device=device, use_deep_features=True, model_name='resnet50')\n",
        "\n",
        "# run reconstruction (tune batch_size, two_opt_iters, top_k for speed/accuracy tradeoff)\n",
        "path, timings = reconstructor.reconstruct(\n",
        "    video_path='jumbled_video.mp4',\n",
        "    output_path='reconstructed.mp4',\n",
        "    batch_size=32,        # larger batch_size -> better GPU utilization\n",
        "    two_opt_iters=200,    # reduce iterations for faster runs\n",
        "    top_k=12              # smaller top_k -> faster but possibly slightly worse\n",
        ")\n",
        "\n",
        "print(\"\\n✅ Reconstruction finished. Output:\", 'reconstructed.mp4')\n",
        "print(\"Timings summary:\")\n",
        "for k,v in timings.items():\n",
        "    print(f\"  {k:20s} : {v:.2f}s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcWYmFTpzmoQ",
        "outputId": "bec18ac4-a073-4057-e353-f89917ab819e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Initializing feature extractor: resnet50\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 190MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature extractor ready on cpu\n",
            "Initialized reconstructor on device=cpu, deep_features=True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Decoding frames: 100%|██████████| 300/300 [00:03<00:00, 93.08f/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 300 frames at 30.00 FPS in 3.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features (batched): 100%|██████████| 10/10 [01:14<00:00,  7.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature extraction done: shape=(300, 2048) time=80.02s\n",
            "Built similarity matrix (N=300) in 0.01s\n",
            "Greedy path computed in 0.01s\n",
            "2-opt limited finished in 37 iterations, time=0.11s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Writing video: 100%|██████████| 300/300 [00:07<00:00, 38.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote video to reconstructed.mp4 in 7.86s\n",
            "Timings: {'decode': 3.2944602966308594, 'feature_extraction': 80.02252984046936, 'similarity_matrix': 0.011424064636230469, 'greedy_path': 0.006487131118774414, 'two_opt': 0.11117029190063477, 'video_writing': 7.860515356063843, 'total': 91.30696988105774}\n",
            "\n",
            "✅ Reconstruction finished. Output: reconstructed.mp4\n",
            "Timings summary:\n",
            "  decode               : 3.29s\n",
            "  feature_extraction   : 80.02s\n",
            "  similarity_matrix    : 0.01s\n",
            "  greedy_path          : 0.01s\n",
            "  two_opt              : 0.11s\n",
            "  video_writing        : 7.86s\n",
            "  total                : 91.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# CELL 5: Download result (Colab helper)\n",
        "# ========================================\n",
        "from google.colab import files\n",
        "print(\"Preparing download...\")\n",
        "files.download('reconstructed.mp4')\n",
        "print(\"Download started.\")\n"
      ],
      "metadata": {
        "id": "CZvTHABw0GQb",
        "outputId": "cdae5eca-36ae-4f35-9f9f-7597af6b658a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing download...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a5f2abcc-59e0-4941-9c23-15835f9d7cc6\", \"reconstructed.mp4\", 56004809)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download started.\n"
          ]
        }
      ]
    }
  ]
}